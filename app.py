import streamlit as st
import subprocess
import os
import sys
import time
import re
from datetime import datetime

# â”€â”€â”€ Add local directory to Python path â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# â”€â”€â”€ Local Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from run_llm import run_llm
from utils.prompt_classifier import classify_prompt
from utils.prompt_router import route_prompt

# â”€â”€â”€ Streamlit Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="PromptForge", layout="centered")

st.markdown("<h1 style='text-align: center;'>ğŸ› ï¸ PromptForge</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'>Sharp, clear, adaptive AI reasoning.</p>", unsafe_allow_html=True)
st.markdown("---")

# â”€â”€â”€ Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "autofill_prompt" not in st.session_state:
    st.session_state.autofill_prompt = ""

# â”€â”€â”€ Prompt Input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
user_prompt = st.text_area("ğŸ’¬ Ask Anything:", height=140, placeholder="e.g. Best taco recipe? Or how to optimize SQL queries?")
run = st.button("ğŸš€ Run")

# â”€â”€â”€ Run Logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if run and user_prompt.strip():
    with st.spinner("â³ Working on your prompt..."):
        start_time = time.time()
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        log_path = f"logs/run_{timestamp}.md"

        try:
            prompt_type = classify_prompt(user_prompt, run_llm)
            with st.expander("ğŸ§  Prompt Type (Auto-Classified)", expanded=False):
                st.markdown(f"Detected: **{prompt_type}**")
        except Exception as e:
            st.error(f"Prompt classification failed: {e}")
            prompt_type = "default"

        mode = route_prompt(user_prompt, prompt_type)

        if mode == "simple":
            response = run_llm(user_prompt)
            elapsed = round(time.time() - start_time, 1)
            st.success(f"âœ… Simple LLM Response in {elapsed} seconds")
            st.markdown(f"### ğŸ§  Answer:\n\n{response}")
        else:
            command = f'python3 main.py "{user_prompt}"'
            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)

            raw_output_lines = []
            cleaned_output_lines = []
            followups = []
            card = st.container()

            current_card = None
            current_card_lines = []
            current_title = ""

            for line in process.stdout:
                raw_output_lines.append(line)
                clean_line = line.strip()

                if clean_line.startswith("/") or "site-packages" in clean_line or "warnings.warn" in clean_line:
                    continue

                if "ğŸ¤” Follow-Up:" in clean_line or "Follow-Up:" in clean_line:
                    followup_matches = re.findall(r"[ğŸ¤”ğŸ“ŒğŸŒ®ğŸ§ ğŸ”ğŸ“ğŸ’¡]?\s*(.+?)(?:\?|$)", clean_line.split("Follow-Up:")[-1])
                    followups.extend([f.strip().strip("?") for f in followup_matches if f.strip()])
                    continue

                if clean_line.startswith("##") or any(step in clean_line.lower() for step in ["step", "response", "revision", "critique", "summary"]):
                    if current_card_lines:
                        with card.expander(current_title or "Step"):
                            st.markdown("\n".join(current_card_lines))
                        current_card_lines = []
                    current_title = clean_line.replace("##", "").strip()
                else:
                    current_card_lines.append(clean_line)

            if current_card_lines:
                with card.expander(current_title or "Step"):
                    st.markdown("\n".join(current_card_lines))

            process.wait()
            elapsed = round(time.time() - start_time, 1)
            st.success(f"âœ… Response Complete in {elapsed} seconds")

            if followups:
                st.markdown("### ğŸ” Suggested Follow-Ups:")
                cols = st.columns(len(followups))
                for i, suggestion in enumerate(followups):
                    with cols[i]:
                        if st.button(suggestion):
                            st.session_state.autofill_prompt = suggestion
                            st.experimental_rerun()

            if os.path.exists(log_path):
                with open(log_path, "r") as f:
                    raw_output = f.read()
                with st.expander("ğŸªµ Raw Output (Debug)", expanded=False):
                    st.code(raw_output)
                with open(log_path, "rb") as f:
                    st.download_button("ğŸ“¥ Download Full Output", f, file_name=os.path.basename(log_path), mime="text/markdown")

else:
    if st.session_state.autofill_prompt:
        user_prompt = st.session_state.autofill_prompt
        st.session_state.autofill_prompt = ""
        st.experimental_rerun()
    else:
        st.info("Enter a prompt above and press **Run** to begin.")
