import sys
import os
from datetime import datetime
from dotenv import load_dotenv

# â”€â”€â”€ Load environment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dotenv_path = os.path.join(os.path.dirname(__file__), '.env')
load_dotenv(dotenv_path)

from llm_client import call_local_llm
from prompt_builder import (
    load_principles,
    build_initial_prompt,
    build_critique_prompt,
    build_deep_dive_prompt,
    build_persona_echo_prompt,
    build_revise_prompt,
    build_second_critique_prompt,
    build_tension_prompt,
    build_meta_soul_prompt,
    build_summary_prompt
)

# â”€â”€â”€ Print formatted section header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def print_section(title):
    print(f"\n\033[95mâœ¦ {title}\033[0m")
    print("-" * (len(title) + 4) + "\n")

# â”€â”€â”€ Truncate long LLM output for display â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def display_truncated_output(output, limit=1000):
    if len(output) > limit:
        print(output[:limit] + "\n... [Truncated]")
    else:
        print(output)

# â”€â”€â”€ Save run to Markdown log â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_markdown_log(prompt, steps):
    os.makedirs("logs", exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    path = f"logs/run_{timestamp}.md"
    with open(path, "w") as f:
        f.write(f"# ğŸŒ± Alignment Run - {timestamp}\n\n")
        f.write(f"## Prompt\n{prompt}\n\n")
        for step in steps:
            f.write(f"## {step['title']}\n{step['output']}\n\n")
    print(f"\nâœ… Output saved to {path}")

# â”€â”€â”€ Main orchestration pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_pipeline(user_prompt):
    steps = []
    principles = load_principles()

    def run_step(title, builder_fn, *args):
        print_section(title)
        prompt = builder_fn(*args)
        output = call_local_llm(prompt, max_tokens=500)
        display_truncated_output(output)
        steps.append({"title": title, "prompt": prompt, "output": output})
        return output

    # â”€â”€â”€ Prompt-type classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    lowered = user_prompt.lower()
    if any(word in lowered for word in ["build", "design", "code", "implement", "api", "database", "tech", "python", "algorithm"]):
        prompt_type = "technical"
    elif any(word in lowered for word in ["justice", "race", "gender", "equity", "identity", "culture", "marginalized"]):
        prompt_type = "social"
    elif any(word in lowered for word in ["startup", "founder", "investor", "fund", "venture", "capital", "business"]):
        prompt_type = "venture"
    else:
        prompt_type = "default"

    print(f"\033[94mğŸ“Œ Detected prompt type:\033[0m {prompt_type}\n")

    # â”€â”€â”€ Step 1: Always run initial prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    initial = run_step("ğŸ§  Step 1: Initial Response", build_initial_prompt, user_prompt)

    # â”€â”€â”€ Steps 2â€“3: Skipped for 'technical' prompts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if prompt_type != "technical":
        critique = run_step("ğŸ” Step 2: Critique v1 (Outsider Principles)", build_critique_prompt, initial, principles)
        deeper_critique = run_step("ğŸ•³ï¸ Step 3: Expand Critique (What's Missing?)", build_deep_dive_prompt, critique)
    else:
        critique = ""
        deeper_critique = ""

    # â”€â”€â”€ Step 4: Perspective shift â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    persona_echo = run_step("ğŸ­ Step 4: Persona Echo (Perspective Shift)", build_persona_echo_prompt, initial)

    # â”€â”€â”€ Step 5: Combine & revise â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    revised = run_step("ğŸ”§ Step 5: Revision (Incorporate All)", build_revise_prompt, initial, critique, deeper_critique, persona_echo)

    # â”€â”€â”€ Steps 6â€“8: Only for deep or social prompts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if prompt_type not in ["technical"]:
        second_critique = run_step("ğŸ” Step 6: Second Critique (Refined Response)", build_second_critique_prompt, revised, principles)
        tensions = run_step("ğŸª Step 7: Reflect on Tensions", build_tension_prompt, revised)
        soul = run_step("ğŸ’€ Step 8: Meta-Soul Check", build_meta_soul_prompt, user_prompt, revised)

    # â”€â”€â”€ Step 9: Always summarize â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    summary = run_step("ğŸ“ˆ Step 9: Growth + Summary", build_summary_prompt, initial, revised)

    # â”€â”€â”€ Save log â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    save_markdown_log(user_prompt, steps)

# â”€â”€â”€ Entry point â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("âŒ Please provide a prompt.")
        sys.exit(1)

    user_prompt = " ".join(sys.argv[1:])
    run_pipeline(user_prompt)
