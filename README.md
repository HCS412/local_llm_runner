ğŸ§  PromptForge
Orchestrated Local Reasoning with LLMs
A fully local, open-source pipeline for structured prompt analysis, critique, and contextual revision. Built for thinkers, hackers, and alignment nerds.

ğŸ’¡ What It Does
PromptForge goes beyond basic prompting. It:

Classifies prompts based on topic, tone, and complexity

Selects dynamic reasoning personas for diverse reflection

Orchestrates a modular pipeline of critique, reframing, and revision

Surfaces tension and multiple perspectives

Returns answers that think deeper â€” all 100% locally

No API keys. No tracking. No cloud calls.
Just reasoning on your machine.

ğŸ”§ Why It Matters
LLMs are too often trained to be helpful, polite, and forgettable.
PromptForge helps them be critical, context-aware, and even soulful.

Itâ€™s a new kind of reasoning tool:

One that shows its work

That critiques itself

That doesn't just echo Silicon Valley defaults

And runs locally for total transparency + ownership

ğŸ§± Key Features
Feature	Description
ğŸ§  Prompt classifier	Auto-detects complexity, topic, tone
ğŸ” Pipeline orchestration	Step-by-step critique + reframe flow
ğŸ­ Dynamic personas	Models respond as barbers, poets, technologists, etc.
ğŸ“Š Confidence scoring	Know how confidently a category is chosen
ğŸ–¼ Expandable Streamlit UI	Clean, card-based outputs with step labels
ğŸ§© Model-agnostic	Works with any local LLM (TinyLLaMA, Mistral, Phi)
ğŸ—‚ Logs everything	All runs saved as structured markdown for later analysis

ğŸ–¥ï¸ Tech Stack
Tool	Purpose
Python 3.9+	Core logic, classification, orchestration
Streamlit	UI frontend
Ollama / LM Studio	Local model runners (GGUF)
TinyLLaMA, Mistral, Phi	Example models
Markdown	Output formatting & logs

ğŸ–¼ Example Flow
Prompt:

â€œWhat should I consider before launching a SaaS business?â€

PromptForge:

Classifies as venture + complex

Chooses relevant reasoning personas

Runs a full multi-step critique pipeline

Surfaces tensions, alternative framings

Revises and finalizes

â†’ Returns layered insight instead of generic tips.

ğŸš€ Quick Start
bash
Copy
Edit
git clone https://github.com/HCS412/local_llm_runner.git
cd local_llm_runner
pip install -r requirements.txt
streamlit run app.py
ğŸ§  Be sure to have a local LLM loaded via LM Studio or Ollama (e.g. TinyLLaMA, Mistral, Phi).

âš™ï¸ Prompt Routing
Type	Description
simple	Short, factual prompts â†’ direct LLM response
full_pipeline	Deeper prompts â†’ critique, personas, revisions

Full Pipeline Stages:
Initial generation

Reasoning critique

Persona reframing

Answer revision

Meta-summary

Follow-up suggestions

Markdown log output

ğŸ“ Directory Overview
bash
Copy
Edit
â”œâ”€â”€ app.py                     # Streamlit frontend
â”œâ”€â”€ main.py                    # CLI runner
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ prompt_router.py       # Pipeline decision logic
â”‚   â”œâ”€â”€ prompt_classifier.py   # Smart classification engine
â”‚   â”œâ”€â”€ dynamic_persona_router.py # Persona selection system
â”‚   â”œâ”€â”€ formatting.py          # Markdown cleanup
â”œâ”€â”€ logs/                      # Markdown logs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ§  Config Tips
ğŸ­ Add more personas in dynamic_persona_router.py

âš¡ Run smaller models for speed, or swap for custom ones

ğŸ”„ Easily plug in sentence embeddings or OpenAI fallback

ğŸª Use markdown logs to analyze model behavior over time

ğŸŒ Example Prompts
bash
Copy
Edit
python main.py "How can I launch a startup with no funding?"
python main.py "Why do people follow controversial public figures?"
python main.py "What should I teach my kids about race and AI?"
ğŸ§­ Roadmap
 Side-by-side model comparisons (TinyLLaMA vs GPT-4)

 FastAPI server mode

 Toggle personas per run

 Memory + prompt history

 External dataset reflection

 User-defined critique stages

ğŸ¤ Contribute
We welcome:

ğŸ§  Philosophers + prompt engineers

ğŸ‘©â€ğŸ”§ Builders + model tinkerers

ğŸ”¬ Researchers on alignment, cognition, or bias

ğŸ§© Creative weirdos and systems thinkers

Open a PR, issue, or idea.

ğŸªª License
MIT.
Build. Remix. Learn. Reflect.
Just donâ€™t put it behind a paywall.
